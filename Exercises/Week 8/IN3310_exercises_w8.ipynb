{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN3310 Week 8\n",
    "### haakongk\n",
    "### 1) Average Precision in Extreme Cases\n",
    "\n",
    "**a) Suppose the set used for evaluation consists of 11 samples of which 3 are actual positives. Those 3 have a *higher* prediction score for the positive class than the other 8 samples. What is the average precision?**\n",
    "\n",
    "**Average Precision** er et mål på kvaliteten til en *rangert liste* med prediksjoner. Den fanger opp rekkefølgen og nøyaktigheten. La:\n",
    "* $r_1, r_2, \\dots, r_N$ være rangeringen (etter score)\n",
    "* $y_i \\in \\{0, 1\\}$\n",
    "* $\\text{Precision@}k$ være andelen positive blant de $k$ første i rangeringen. Da:\n",
    "\n",
    "$$\\text{AP} = \\frac{1}{\\text{antall faktisk positive}}\\sum_{k=1}^{N} \\text{Precision}(k) \\cdot 1_{y_k = 1}$$\n",
    "\n",
    "La oss si at de tre **actual positives** ligger øverst i listen av prediksjoner, altså på plass $1, 2, 3$. Da vil vi få\n",
    "$$\\text{AP} = \\frac{1}{\\text{3}}\\sum_{k=1}^{11} \\text{Precision}(k) \\cdot 1_{y_k = 1} = \\frac{1}{3}\\cdot \\left(\\frac{1}{1} \\cdot 1.0 + \\frac{2}{2} \\cdot 1.0 + \\frac{3}{3} \\cdot 1.0\\right) = 1.0$$\n",
    "\n",
    "Vi blir altså belønnet for at de gode prediksjonene ligger tidlig i lista ved AP, at modellen finner dem raskt. **Hvorfor? Fordi vi ønsker et kvalitativt mål på hvor godt modellen prioriterer de faktiske positive over de negative. Det belønner tidlig presision, og krever ikke at datasettet er balansert.**\n",
    "\n",
    "**b) Suppose the set consists of 11 samples, of which 3 are actual positives. Those 3 have a *lower* prediction score for the positive class than the other 8 samples. What is the average precision?**\n",
    "\n",
    "Dersom de har lavere prediksjons-score vil de havne lenger ned i rangeringen som AP gjør. Dermed vil de bli straffet for dette, ved f.eks.\n",
    "\n",
    "$$\\text{AP} = \\frac{1}{\\text{3}}\\sum_{k=1}^{11} \\text{Precision}(k) \\cdot 1_{y_k = 1} = \\frac{1}{3}\\cdot \\left(\\frac{1}{11} \\cdot 1.0 + \\frac{2}{12} \\cdot 1.0 + \\frac{3}{13} \\cdot 1.0\\right) = 0.163$$\n",
    "\n",
    "**c) Suppose the set used for evaluation consists of $N$ samples, of which $R$ are actual positives, and those $R$ samples have *lower* prediction scores for the positive class than the other N - R samples. What is the average precision?**\n",
    "\n",
    "Her kan vi bruke formelen igjen, og sette inn for $R$ og $N$, slik at vi får en generell formel\n",
    "\n",
    "$$\\text{AP} = \\frac{1}{\\text{R}}\\sum_{k=1}^{N} \\text{Precision}(k) \\cdot 1_{y_k = 1} = \\frac{1}{R} \\sum_{j=1}^{R} \\frac{j}{N - R + j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
