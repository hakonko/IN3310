{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e559983-c9a7-43b1-9a60-6ed50e71fd3f",
   "metadata": {},
   "source": [
    "**Part a)** The first part is to split the data into three sets: training, validation, and test. Split each class separately so that there is an equal percentage of each class in all three sets. The number of total images in the validation is to be roughly 2000, in the test set 3000, and the remainder for the training set. It does not need to be exact. This is called a stratified split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b3ab57c-d1aa-4c7a-91bb-d6c1d77ac4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380fc8e-f7d9-44b4-b69c-c5c1d1e79a59",
   "metadata": {},
   "source": [
    "First, we decide the classes. `.parts[-1]` gets out the last part in the directory, whilst `.iterdir()` iterates through directories, and `.is_dir()` sees to it, that it really is a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb678f4-9d26-43fc-9c32-4c2f8c0f4806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forest', 'buildings', 'sea', 'glacier', 'mountain', 'street']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Path('/mnt/e/ml_projects/IN3310/2025/tut_data/mandatory1_data/')\n",
    "\n",
    "classes = [str(subdir.parts[-1]) for subdir in dataset.iterdir() if subdir.is_dir()]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a0a9a-6901-443c-bd5f-a8c3d2d3d68b",
   "metadata": {},
   "source": [
    "Then, we create directories for `train, val, test` in the root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd4883f-0afe-47fc-b2ab-881b8ce4193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/mnt/e/ml_projects/IN3310/2025/tut_data/oblig1/')\n",
    "\n",
    "# the directories we want to create\n",
    "dirs = ['train', 'val', 'test']\n",
    "\n",
    "for dir_name in dirs:\n",
    "    # creating a path string\n",
    "    dir_path = base_path / dir_name\n",
    "    dir_path.mkdir(parents=True, exist_ok=True) # creating directory\n",
    "\n",
    "    # creating subdirectories of class names\n",
    "    for class_name in classes:\n",
    "        class_path = base_path / dir_name / class_name\n",
    "        class_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50850386-5c69-4b13-8f4d-a280eb732d11",
   "metadata": {},
   "source": [
    "Now we need to split the data into train, test, vals. A good way of doing this is to use `train_test_split` of the filenames and classes, and then fill our folders up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c35411d-187a-4f13-81f1-161bc1d65d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = [] # container for image paths\n",
    "class_indices = [] # container for class indices\n",
    "\n",
    "for class_index, class_name in enumerate(classes):\n",
    "    class_path = dataset / class_name\n",
    "    for img_file in class_path.iterdir():\n",
    "        if img_file.is_file():\n",
    "            img_paths.append(img_file)\n",
    "            class_indices.append(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8433620-194f-47fa-b52f-e2579578ddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, temp_imgs, train_indices, temp_indices = train_test_split(\n",
    "    img_paths, class_indices, test_size=0.3, stratify=class_indices, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0c73ca-affb-408f-b841-63fe01e876c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs, test_imgs, val_indices, test_indices = train_test_split(\n",
    "    temp_imgs, temp_indices, test_size=0.6, stratify=temp_indices, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abcc291-cf10-4e39-b974-c3bd7c647fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images(img_paths, class_indices, split_name):\n",
    "    \n",
    "    for img_path, class_index in zip(img_paths, class_indices):\n",
    "        target_dir = base_path / split_name / classes[class_index]\n",
    "        target_file = target_dir / img_path.name\n",
    "\n",
    "        # copying the file if it's not already there\n",
    "        if not target_file.exists():\n",
    "            shutil.copy(img_path, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5305f96b-6939-4b56-b1ce-11c3c2af73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_images(train_imgs, train_indices, 'train')\n",
    "copy_images(val_imgs, val_indices, 'val')\n",
    "copy_images(test_imgs, test_indices, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f206b9-c2e8-4654-ab93-79dce611e88a",
   "metadata": {},
   "source": [
    "We now have folders with the data. Finally we can do a check for duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f151c51",
   "metadata": {},
   "source": [
    "**Part b)** Create a solution to verify that the dataset splits are disjoint. Ensure that no file appears in more than one of your training, validation, or\n",
    "test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d7c9e8-611f-48b2-b086-49637bc7503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_no_duplicates(train_imgs, val_imgs, test_imgs):\n",
    "    train_set = set(train_imgs)\n",
    "    val_set = set(val_imgs)\n",
    "    test_set = set(test_imgs)\n",
    "\n",
    "    # using intersection to check for data overlaps\n",
    "    assert len(train_set.intersection(val_set)) == 0, 'Overlap between Train and Val'\n",
    "    assert len(train_set.intersection(test_set)) == 0, 'Overlap between Train and Test'\n",
    "    assert len(val_set.intersection(test_set)) == 0, 'Overlap between Val and Test'\n",
    "\n",
    "verify_no_duplicates(train_imgs, val_imgs, test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8a0ee-1872-44ec-a549-1920ef618276",
   "metadata": {},
   "source": [
    "**Part c)** Develop and implement dataloaders for training, validation, and test sets. Please make one root path for the dataset, this makes it easier for us\n",
    "to check/debug your work. If there are multiple paths to the dataset that we need to change, it becomes tricky to change them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "346cb022-7f81-4364-bb36-a3147f831eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(), # converts to a torch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # normalizes to [-1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b10f1b7-b298-4310-9a6e-cb2afafbed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=base_path / 'train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder(root=base_path / 'val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=base_path / 'test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (in3310)",
   "language": "python",
   "name": "in3310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
